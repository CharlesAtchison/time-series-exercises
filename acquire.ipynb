{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2dad9ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, os, io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476723a",
   "metadata": {},
   "source": [
    "### 1. Using the code from the lesson as a guide and the REST API from https://python.zgulde.net/api/v1/items as we did in the lesson, create a dataframe named `items` that has all of the data for items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92826a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_data():\n",
    "    url = 'https://python.zgulde.net/api/v1/items'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    filename = 'items.csv'\n",
    "    if os.path.isfile(filename):\n",
    "        items = pd.read_csv(filename, index_col=[0])\n",
    "    else:\n",
    "        if response.ok:\n",
    "            data = response.json()\n",
    "            items = pd.DataFrame(data['payload']['items'])\n",
    "            items.to_csv(filenamename)\n",
    "        else:\n",
    "            print(response.status_codeus_code)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b85ae5",
   "metadata": {},
   "source": [
    "### 2. Do the same thing, but for `stores` (https://python.zgulde.net/api/v1/stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c15763b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stores_data():\n",
    "    url = 'https://python.zgulde.net/api/v1/stores'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    filename = 'stores.csv'\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        stores = pd.read_csv(filename, index_col=[0])\n",
    "    else:\n",
    "        if response.ok:\n",
    "            data = response.json()\n",
    "            stores = pd.DataFrame(data['payload']['stores'])\n",
    "            stores.to_csv(filename)\n",
    "        else:\n",
    "            print(response.status_codeus_code)\n",
    "    return stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1794b21",
   "metadata": {},
   "source": [
    "### 3a. Extract the data for `sales` (https://python.zgulde.net/api/v1/sales). There are a lot of pages of data here, so your code will need to be a little more complex. Your code should continue fetching data from the next page until all of the data is extracted.\n",
    "\n",
    "### 3b. Save the data in your files to local csv files so that it will be faster to access in the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94ce65f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_sales_data():\n",
    "    url = 'https://python.zgulde.net/api/v1/sales'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    filename = 'sales.csv'\n",
    "    if os.path.isfile(filename):\n",
    "        sales = pd.read_csv(filename, index_col=[0])\n",
    "    else:\n",
    "        if response.ok:\n",
    "            extracted_data = list()\n",
    "            payload = response.json()['payload']\n",
    "            while (payload['next_page'] is not None):\n",
    "                extracted_data.extend(payload['sales'])\n",
    "                new_url = url[:25] + payload['next_page']\n",
    "                print(new_url)\n",
    "                response = requests.get(new_url)\n",
    "                payload = response.json()['payload']\n",
    "            sales = pd.DataFrame(extracted_data)\n",
    "            sales.to_csv(filename)\n",
    "\n",
    "        else:\n",
    "            print(response.status_codeus_code)\n",
    "    return sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f737108a",
   "metadata": {},
   "source": [
    "### 4. Combine the data from your three separate dataframes into one large dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a287cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(sales, items, stores):\n",
    "    sales = sales.rename(columns={'store': 'store_id', 'item': 'item_id'})\n",
    "    df = sales.join(stores.set_index('store_id'), on='store_id')\n",
    "    df = df.join(items.set_index('item_id'), on='item_id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca2a5b",
   "metadata": {},
   "source": [
    "### 5. Acquire the Open Power Systems Data for Germany, which has been rapidly expanding its renewable energy production in recent years. The data set includes country-wide totals of electricity consumption, wind power production, and solar power production for 2006-2017. You can get the data here: https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "90c008df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_power_data():\n",
    "    url = 'https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv'\n",
    "    response = requests.get(url)\n",
    "    filename = 'power_data.csv'\n",
    "    if os.path.isfile(filename):\n",
    "        df = pd.read_csv(filename, index_col=[0])\n",
    "    else:\n",
    "        if response.ok:\n",
    "            data = response._content\n",
    "            print(data)\n",
    "            df = pd.read_csv(io.BytesIO(data), encoding='utf8')\n",
    "            df.to_csv(filename)\n",
    "        else:\n",
    "            print(response.status_code)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
